embedding:
  model: "all-MiniLM-L6-v2"
  device: "cpu"
  
retrieval:
  top_k: 5
  similarity_threshold: 0.7

chunking:
  chunk_size: 512
  chunk_overlap: 50

llm:
  model: "gpt-3.5-turbo"
  temperature: 0.1
  max_tokens: 1000
